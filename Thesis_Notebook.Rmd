---
title: "R Notebook"
output: html_notebook
---

Libraries: 

```{r}
#install.packages('mosaic')
#install.packages('data.table')
#install.packages('magrittr')
#install.packages('tidyr')
#install.packages('dplyr')
#install.packages("Hmisc")
#install.packages("corrplot")
#install.packages("PerformanceAnalytics")


library(data.table)
library(magrittr)
library(tidyr)
library(dplyr)
library(mosaic)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
```


Datenimport:

```{r}

HH_file<- file.path('Data/MiD2017_Haushalte.csv')
HH_dt <- fread(HH_file)
HH_dt <- as.data.table(HH_dt)


Person_file <- file.path('Data/MiD2017_Personen.csv')
Person_dt <- fread(Person_file)
Person_dt <- as.data.table(Person_dt)

```


# Überprüfen Haushalts IDs mit PersonenIDs
# zu jedem Haushalt gibt es Personen
```{r}
ids_HH <- HH_dt[, "H_ID"] # 156240
ids_P <- Person_dt[, "H_ID"]
unique_ids_P <- unique(ids_P) # 156240
count(unique_ids_P)
count(ids_HH)
```

# Wie viele Haushalte mit 1,2,3,4 autos gibt es: 
```{r}
dplyr::count(HH_dt, anzauto_gr1)
3424/156420
# nur ca. 2 % der HH haben 4 Autos und mehr -> es reicht die Untergliederung bis 3 und mehr Autos zu verwenden 
```

Wieviele Haushalte machen keine Angabe:

```{r}
dplyr::count(HH_dt, auto)
```
14 Haushalte machen keine Angabe --> aus Datensatz entfernen :

```{r}

HH_dt <- filter(HH_dt, anzauto_gr2 != 9 )
```


Spalten aus HH_dt löschen die nicht benötigt werden 

```{r}
HH_dt <- as.data.table(HH_dt)
HH_dt[, c("H_GEW","H_HOCH"):=NULL]
# Gründe für nicht Besitz, pkw segment, bundesland, andere variablen zu einkommen (71-77), pkw_jahresfl)
HH_dt <- HH_dt[, -c(62:66,86,87,90,91,71:73, 75:77, 88)]
HH_dt[, c("MODE","BASISAUF", "TEILSTP", "H_NEBEN_1","H_NEBEN_2","H_NEBEN_3","H_NEBEN_4","H_NEBEN_5", "H_NEBEN_6", "H_NEBEN_7","H_NEBEN_8", "anzneben", "nebenws", "H_NOCAR_A" ):=NULL]
HH_dt[, "hausnutz":=NULL]
HH_dt[, "wohnlage":=NULL]
HH_dt[, c("RegioStaR2","RegioStaR17"):=NULL]
HH_dt[, "H_MIETE":=NULL]
HH_dt[, "H_ART":=NULL]
# Geschlecht
HH_dt <- HH_dt[, -c(5:12)]
#andere anz_auto infos
HH_dt[, c("anzauto_gr1","anzauto_gr3"):=NULL]
HH_dt[, "H_ANZAUTO":= NULL]
# nur auto ja oder nein 
HH_dt[, "M_CAR":= NULL]
```

Daten aus Personenset hinzuziehen: 

1. Höchster Bildungsabschluss

```{r}
bildung_dt <- Person_dt[, c("H_ID", "P_BIL")]
Anzahl_HH <- unique(bildung_dt[, "H_ID"])
count(Anzahl_HH)
bildung_ohneProxy <- bildung_dt[P_BIL != "206" & P_BIL!= "9"]
Anzahl_HH_ohneProxy <- unique(bildung_ohneProxy[, "H_ID"])
count(Anzahl_HH_ohneProxy)

maxbildung_byHH <- max(P_BIL ~ H_ID, data = bildung_ohneProxy)
maxbildung_dt <- as.data.table(data.frame(HH_ID=names(maxbildung_byHH), maxBildung=maxbildung_byHH, row.names=NULL))
str(maxbildung_dt)

dplyr::count(maxbildung_dt, maxBildung)
## 6 ( = anderer Abschluss)?


mean(maxbildung_dt$maxBildung) 
# damit ersetzen?


```

2. Anzahl Wege insgesamt am Stichtag

```{r}
#anzwege2 sind die Anzahl Wege insgesamt (inkl. weiterer Wege aber ohne rbw(busfahrer etc.))
Wege_dt <- Person_dt[, c("H_ID", "anzwege1", "arbwo", "feiertag")]

#nur Personen mit bekannter Mobilität bzw. wegeerfassung
Wege_clean <- Wege_dt[anzwege1 != "803" & anzwege1!= "804"]

#nur Personen der Stichtag ein Wochentag war
Wege_Wochentage <- Wege_clean[arbwo == 1 & feiertag == 0]

x <- sum(anzwege1 ~ H_ID, data = Wege_Wochentage)
anzahlWege_dt <- as.data.table(data.frame(HH_ID=names(x), anzahlWege=x, row.names=NULL))
dplyr::count(anzahlWege_dt, anzahlWege)

unique(anzahlWege_dt$HH_ID)
# noch ca. 100.000 HH vorhanden
summary(anzahlWege_dt)
# sehr hohe Werte rausnehmen ? 60?

#wie mit jetzt fehlenden haushalten umgehen -> einfach raus oder imputieren?
```

3. Länge der Wege am Stichtag

```{r}
#perskm2 enthält länge aller wege mit weiteren wegen ohne rbw, fehlende werte wurden imputiert
Weglänge_dt <- Person_dt[, c("H_ID", "perskm2", "arbwo", "feiertag")] 

summary(Weglänge_dt)
Weglänge_dt$perskm2

# wie mit "80802 - person hat nur rbw" umgehen? -> raus ca. 2600

Weglänge_clean <- Weglänge_dt[perskm2 != "80803" & perskm2!= "80804" & perskm2 != "80802"]

# perskm2 is a character column, we need to convert it to numeric to be able to sum it up
Weglänge_clean$perskm2 <- sub("," , ".", Weglänge_clean$perskm2)
Weglänge_clean$perskm2 <- as.numeric(Weglänge_clean$perskm2)

#summary(Weglänge_clean)
#dplyr::count(Weglänge_clean, anzkm == 9995)
#Weglänge_clean <- filter(Weglänge_clean, anzkm != 9995)

x <- sum(perskm2 ~ H_ID, data = Weglänge_clean)
gesamteWeglänge_dt <- as.data.table(data.frame(HH_ID=names(x), perskm2=x, row.names=NULL))
#dplyr::count(gesamteWeglänge_dt, anzkm > 500)
gesamteWeglänge_dt2 <- filter(gesamteWeglänge_dt, perskm2 < 1000)
summary(gesamteWeglänge_dt2)
#gesamteWeglänge_dt2$anzkm <- log(gesamteWeglänge_dt2$anzkm)
# transform -inf to zero 
#gesamteWeglänge_dt2[gesamteWeglänge_dt2 == -Inf] <- 0
#summary(gesamteWeglänge_dt2)
#qqnorm(gesamteWeglänge_dt2$anzkm, pch = 1, frame = FALSE)
#qqline(gesamteWeglänge_dt2$anzkm, col = "steelblue", lwd = 2)

#unique(gesamteWeglänge_dt$HH_ID)

```  

Alle 3 Merkmale zusammen in eine data table

```{r}
#1. maxBildung_dt 
# 4600 Leute mit anderer Bildung ?

#2. anzahlWege_dt

combined2_df <- merge(x=maxbildung_dt,y=anzahlWege_dt,by="HH_ID")

#3. gesamteWeglänge_dt

combined3_df <- merge(x=combined_df, y=gesamteWeglänge_dt2, by="HH_ID")

  
```

Anzahl berufstätiger Personen im HH

HP_TAET_1 bis HP_TAET_8

berufstätig:
1: Vollzeit berufstätig
2: Teilzeit berufstätig, d.h. 18 bis unter 35 Stunden pro Woche
3: geringfügig beschäftigt
4: berufstätig als Nebentätigkeit oder im Praktikum
5: berufstätig ohne Angabe zum Umfang

```{r}

taet_dt <- HH_dt[, 12:19]
summary(taet_dt)
taet_dt <- as.data.table(taet_dt)

temp_beruf <- taet_dt < 6 & taet_dt > 0
temp_beruf <- as.data.table(temp_beruf)
temp_beruf <- temp_beruf*1
sum_berufstätige <- apply(temp_beruf,1,sum)
HH_dt$berufstaetige <- sum_berufstätige

# temp vector

#cols <- c(1:8)
#rows <- c(1:nrow(taet_dt))
#for (row in rows){
 # for (col in cols) {
#      if (taet_dt[row, ..col] == 1 || taet_dt[row, ..col] == 2 || taet_dt[row, ..col] == 3 ||taet_dt[row, ..col] == 4    ||taet_dt[row, ..col] == 5) {
#  res[row] <- res[row] + 1
     
    
  #  }
 #   
  #}
  
#} 



# taetigkeitsspalten raus
HH_dt <- HH_dt[, -c(12:19)]
  
```

Anzahl Führerscheinbesitzer

```{r}
HH_dt <- filter(HH_dt, HP_ANZFS != 99 &HP_ANZFS != 94 )
dplyr::count(HH_dt, HP_ANZFS)
HH_dt <- as.data.table(HH_dt)
# entfernen Spalte anzfs in gruppen
HH_dt[, "anzfs_gr":= NULL]
```

HH-Größe

```{r}
HH_dt <- as.data.table(HH_dt)
HH_dt[, "hhgr_gr":= NULL]
setnames(HH_dt, "H_GR", "hhsize")
```


Alter der Haushaltsmitglieder

```{r}

#NOCH 999 entfernen (nächster Durchlauf)!
HH_dt <- filter(HH_dt, HP_ALTER_1 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_2 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_3 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_4 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_5 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_6 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_7 != 999 )
HH_dt <- filter(HH_dt, HP_ALTER_8 != 999 )


alter_dt <- HH_dt[, 2:10]
alter_dt[, "share2039"] <- 0
alter_dt[, "share4064"] <- 0
alter_dt[, "share65"] <- 0

summary(alter_dt)
is.data.table(alter_dt)
# alle numerisch und ist data table

# für 20-39 jährige:
temp <- alter_dt[,2:9]

result <- temp < 40 & temp > 19
result <- as.data.table(result)
result <- result*1
result
anzahl2039 <- apply(result,1,sum)
share2039 <- anzahl2039/ alter_dt[,1]
alter_dt$share2039 <- share2039

# für > 65 jährige

result2 <- temp > 64 & temp < 150
result2 <- as.data.table(result2)
result2 <- result2*1
anzahl65 <- apply(result2,1,sum)
share65 <- anzahl65/ alter_dt[,1]
alter_dt$share65 <- share65

# für 40 - 64 jährige

result3 <- temp < 65 & temp > 39
result3 <- as.data.table(result3)
result3 <- result3*1
anzahl4064 <- apply(result3,1,sum)
share4064 <- anzahl4064/ alter_dt[,1]
alter_dt$share4064 <- share4064

HH_dt[, "share2039"] <- 0
HH_dt[, "share4064"] <- 0
HH_dt[, "share65"] <- 0

HH_dt$share2039 <- share2039
HH_dt$share4064 <- share4064
HH_dt$share65 <- share65

HH_dt <- HH_dt[, -c(3:10)]

```

Household lifecycle stage / children?

 (a) single (1 if household consists of one member, 0 otherwise), (b) couple, (c) couple with children, (d) single parent (1 if the household consists of 1 adult and one or more children, 0 otherwise) and (e) extended families or unattached individuals. 
 
hhtyp : 1 - 11
95 rauswerfen 

1: 18-29
2:1-Personen-HH: Person 30-59 Jahre 
3:1-Personen-HH: Person 60 Jahre und älter -> single
4:2-Personen-HH: jüngste Person 18-29 Jahre
5:2-Personen-HH: jüngste Person 30-59 Jahre
6:2-Personen-HH: jüngste Person 60 Jahre und älte->couple
7:HH mit mind. 3 Erwachsenen -> extended family
8:HH mit mind. einem Kind unter 6 Jahren 
9:HH mit mind. einem Kind unter 14 Jahren 
10:HH mit mind. einem Kind unter 18 Jahren -> couple with children
11:Alleinerziehende(r) -> single parent
95:nicht zuzuordnen

```{r}
HH_dt <- filter(HH_dt, hhtyp != 95 )

hhtyp_dt <- HH_dt[, "hhtyp"]
hhtyp_dt <- as.data.table(hhtyp_dt)
hhtyp_dt[, "single"] <- 0
hhtyp_dt[, "couple"] <- 0
hhtyp_dt[, "couple_children"] <- 0
hhtyp_dt[, "singleparent"] <- 0
hhtyp_dt[, "otherindividuals"] <- 0


# Singles
temp2 <- hhtyp_dt[,1]

single <- temp2 < 4
single <- as.data.table(single)
single <- single*1
hhtyp_dt$single <- single

# Couples

couple <- temp2 < 7 & temp2 > 3
couple <- as.data.table(couple)
couple <- couple *1
hhtyp_dt$couple <- couple 

# Couples with children

couple_c <- temp2 < 11 & temp2 > 7
couple_c <- as.data.table(couple_c)
couple_c <- couple_c*1
hhtyp_dt$couple_children <- couple_c

# singleparent

singleparent <- temp2 == 11
singleparent <- as.data.table(singleparent)
singleparent <- singleparent*1
hhtyp_dt$singleparent <- singleparent

# otherindividuals

others <- temp2 == 7
others <- as.data.table(others)
others <- others*1
hhtyp_dt$otherindividuals <- others

#anhängen 

HH_dt[, "single"] <- 0
HH_dt[, "couple"] <- 0
HH_dt[, "couple_children"] <- 0
HH_dt[, "single_parent"] <- 0
HH_dt[, "other_ind"] <- 0

HH_dt[, "single"] <- single
HH_dt[, "couple"] <- couple
HH_dt[, "couple_children"] <- couple_c
HH_dt[, "single_parent"] <- singleparent
HH_dt[, "other_ind"] <- others

HH_dt <- as.data.table(HH_dt)
HH_dt[, "hhtyp":= NULL]
HH_dt[, "hhtyp2":= NULL]
```

Anzahl Kinder

```{r}
# anzkind18: verwendung der anzahl kinder unter 18 (benötigen eventuell mobilität)
# alle anderen entfernen
HH_dt[, "anzkind06":= NULL]
HH_dt[, "anzkind14":= NULL]
HH_dt[, "anzerw14":= NULL]
HH_dt[, "anzerw18":= NULL]
```


Anzahl andere Fortbewegungsmittel

```{r}
# H_ANZMOTMOP : anzahl an motorräder, mopeds, mofas im HH
# alle anderen entfernen:
HH_dt[, "auto":= NULL]
HH_dt[, "H_ANZMOT":= NULL]
HH_dt[, "H_ANZMOP":= NULL]
HH_dt[, "anzmotmop_gr":= NULL]
HH_dt[, "motmop":= NULL]

#anzpedrad: anzahl elektrofahrrad, pedelecs, fahrräder im HH
HH_dt[, "H_ANZPED":= NULL]
HH_dt[, "H_ANZRAD":= NULL]
HH_dt[, "anzped_gr":= NULL]
HH_dt[, "anzrad_gr":= NULL]
HH_dt[, "anzpedrad_gr":= NULL]
HH_dt[, "pedrad":= NULL]

# mobtyp somit schon über andere variablen vorhanden
HH_dt[, "mobtyp":= NULL]
```


Gebäudetyp

```{r}
# haustyp: 1 ein-bis zweifamilienhaus, 2 mehrfamilienhaus, 3 geschosswohnungsbau, 4 sonstiges, 95 nicht zuzuordnen
# what to do with 95?
dplyr::count(HH_dt, haustyp)
#HH_dt <- filter(HH_dt, haustyp != 95)

# garage: 0 nein, 1 ja, 95 nicht zuzuordnen
# what to do with 95?
dplyr::count(HH_dt, garage)
#HH_dt <- filter(HH_dt, garage != 95)

```


ÖPNV Variablen

bus28: luftlinienentfernung zur nächsten bushaltestelle mit mind. 28 abfahrten am werktag
tram 28 ""
bahn 28 ""
quali_opnv

quali_nv -> nähe zu apotheken etc.

```{r}
#pkw fahrzeit zum nächste ober- und mittelzentrum entfernen:
HH_dt <- as.data.table(HH_dt)
HH_dt[, "min_ozmz":= NULL]  
```

Raumtyp

```{r}
#politische gemeindegrößenklasse entfernen
HH_dt[, "POLGK":= NULL]  
HH_dt[, "RegioStaRGem7":= NULL]  
HH_dt[, "RegioStaR7":= NULL]  
HH_dt[, "RegioStaR4":= NULL]  
HH_dt[, "GEMTYP":= NULL]
HH_dt[, "SKTYP":= NULL]
# oder SKTYP:
#kreisfreie Großstadt
#städtischer Kreis
#ländlicher Kreis mit Verdichtungsansätnze
#dünn besiedelter ländlicher Kreis

#oder RegiostarGem5:
#Metropole
#Regiopole, Großstadt
#zentrale Stadt, Mittelstadt 
#städtischer Raum
#kleinstädtischer, dörflicher Raum  
```

Carsharing

Abgebildet durch H_CS:
1 ja, bei einem Anbieter
2 ja, bei mehreren Anbietern 
3 nein, gar nicht
9 keine Angabe

Sonstige Entfernungen
```{r}
# zu verzerrend, in andere variablen enthalten
HH_dt[, "nocar":= NULL]
HH_dt[, "pkw_jahresfl_gr":= NULL]
```

anzahl wege, länge wege und bildung anhängen 

```{r}
HH_dt <- as.data.table(HH_dt)
setnames(HH_dt, "H_ID", "HH_ID")
HH_dt$HH_ID <- factor(HH_dt$HH_ID)
HH_dt_final <- merge(x=combined3_df, y=HH_dt, by="HH_ID")

HH_dt_final <- filter(HH_dt_final, quali_nv != 95)
dplyr::count(HH_dt_final, haustyp)
dplyr::count(HH_dt_final, garage)
dplyr::count(HH_dt_final, quali_nv)
dplyr::count(HH_dt_final, quali_opnv)
dplyr::count(HH_dt_final, bus28)
dplyr::count(HH_dt_final, tram28)
dplyr::count(HH_dt_final, bahn28)

#train a model to impute values?
```

durchschnittliche weglänge dazu 
```{r}

HH_dt_final$Weglänge_avg <- HH_dt_final$perskm2/HH_dt_final$anzahlWege

#Nan durch 0 ersetzen 
HH_dt_final[is.na(HH_dt_final)] <- 0

summary(HH_dt_final$Weglänge_avg)
HH_dt_final$Weglänge_avg <- log(HH_dt_final$Weglänge_avg)

# transform -inf to zero 
HH_dt_final[HH_dt_final == -Inf] <- 0

```

summary(HH_dt_final$anzkm)
summary(HH_dt_final$anzahlWege)

Testing correlation

```{r}

#Numerische Variablen mit numerischen variablen

# correlation between numerical variables
# spearman correlation coefficient

numerical_dt <- HH_dt_final[, c("anzahlWege","perskm2", "H_ANZMOTMOP", "anzpedrad", "HP_ANZFS", "anzkind18", "berufstaetige", "share4064", "share65","share2039", "Weglänge_avg")]

result <- cor(numerical_dt, method = "spearman")
round(result, 2)

result2 <- rcorr(as.matrix(numerical_dt), type="spearman")
result2

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

flattenCorrMatrix(result2$r, result2$P)

# Insignificant correlation are crossed
corrplot(result2$r, type="upper", order="hclust", 
         p.mat = res2$P, sig.level = 0.01, insig = "blank")
# Insignificant correlations are leaved blank
corrplot(result2$r, type="upper", order="hclust", 
         p.mat = res2$P, sig.level = 0.01, insig = "blank")

chart.Correlation(numerical_dt, histogram=TRUE, pch=19)

```

```{r}
#Kategorische Variablen 
#Using Cramer's V if one variable is more than 2, if both are dichotomous: cramers phi
#can be used for nominal and ordinal variables

#Packages for Cramers V 
install.packages("vcd")
library(vcd)

# import all categorical columns
categorical_dt <- HH_dt_final[, c("H_CS","hheink_gr2", "bus28", "tram28", "bahn28", "haustyp", "garage", "quali_opnv", "quali_nv","single", "couple", "couple_children", "single_parent", "other_ind", "RegioStaRGem5", "maxBildung")]
categorical_dt <- as.data.frame(categorical_dt)

# convert into factor columns
for(i in 1:ncol(categorical_dt)){

categorical_dt[,i] <- as.factor(categorical_dt[,i])

}

#calculate Cramers_V for all pairs of categorical variables in the table:
categorical_dt <- as.data.frame(categorical_dt)
cv <- function(x, y) {
  t <- table(x, y)
  print(t)
  chi <- suppressWarnings(chisq.test(t))$statistic
  cramer <- sqrt(chi / (NROW(x) * (min(dim(t)) - 1)))
  cramer
}

get.V3<-function(y, fill = TRUE){
  col.y<-ncol(y)
  V<-matrix(ncol=col.y,nrow=col.y)
  for(i in 1:(col.y - 1)){
    print(i)
    for(j in (i + 1):col.y){
      print(j)
      V[i,j]<-cv(y[,i],y[,j])
    }
  }
  diag(V) <- 1 
  if (fill) {
    for (i in 1:ncol(V)) {
      V[, i] <- V[i, ]
    }
  }
  V
}
test <- get.V3(categorical_dt)

test <- as.data.frame(test)
colnames(test) <- colnames(categorical_dt)
rownames(test) <- colnames(categorical_dt)

# add degress of freedom
levels <- c(1:ncol(categorical_dt))
for(i in 1:ncol(categorical_dt)){

levels[i] <- nlevels(categorical_dt[,i])

}

test$df <- levels
test <- rbind(round(levels,0),test)

# check thresholds:
#http://www.real-statistics.com/chi-square-and-f-distributions/effect-size-chi-square/
  



```

```{r}
#correlation between numerical and nominal variables 
# numerische variable weglänge_avg mit allen kategoriellen variablen die nicht ordinal sind (e.g. CS, bildung, etc.)

boxplot(qualinv_avgweg$Weglänge_avg ~ qualinv_avgweg$quali_nv)
boxplot(qualinv_avgweg$Weglänge_avg)

library(dplyr)

table_var <- group_by(qualinv_avgweg, quali_nv) %>%
  summarise(
    count = n(),
    mean = mean(Weglänge_avg, na.rm = TRUE),
    variance = var(Weglänge_avg, na.rm = TRUE),
    sd = sd(Weglänge_avg, na.rm = TRUE),
  )
table_var$var_before <- var(qualinv_avgweg$Weglänge_avg)
table_var$sd_before <- sd(qualinv_avgweg$Weglänge_avg)
table_var
#-> variance after grouping still at the same level: no correlation


```


```{r}
# Andere überlegungen numerical vs. nominal 
# alles in dummy variablen umwandeln, ein level rauslassen, e.g 7 levels, 6 dummys
# Korrelation zwischen kategorischen und numerischen variablen 

# wenn numerische variable ordinal ist (1-6) dann kann ich spearman verwenden 

 #income, which is specified as a quadratic to allow for nonlinear effects


# anova - test durchführen oder kruskal walis test
# voraussetzungen:
# anova: normalerverteilte pro kategorie und homogene varianz 
# kruskal_wallis: ohne normalerverteilungsannahmen etc. 
# if only 2 categoris: mann-whitney-U / wilcoxon rank sum test



#Beispiel quali_nv: categories 1-4
  
qualinv_avgweg <- HH_dt_final[, c("quali_nv", "Weglänge_avg")]



qualinv_avgweg1 <- filter(qualinv_avgweg, quali_nv == 1)

# check normal distribution of each category
# qq plot:
qqnorm(qualinv_avgweg1$Weglänge_avg, pch = 1, frame = FALSE)
qqline(qualinv_avgweg1$Weglänge_avg, col = "steelblue", lwd = 2)

# homogene varianz der distributions : levene test or boxplot
#library(car)
boxplot(qualinv_avgweg$Weglänge_avg ~ qualinv_avgweg$quali_nv)
boxplot(qualinv_avgweg$Weglänge_avg)
#leveneTest(Weglänge_avg ~ quali_nv, data = qualinv_avgweg)

# do anova test

aov1 = aov(singleavgweg$Weglänge_avg ~ singleavgweg$single)
summary(aov1)

# pairwise wilcoxon test: # however with large sample sizes even small differences will be significant
qualinv_avgweg$quali_nv <-as.factor(qualinv_avgweg$quali_nv)
pairwise.wilcox.test(qualinv_avgweg$Weglänge_avg,qualinv_avgweg$quali_nv,exact=F)
#p.adj='bonferroni'
summary(qualinv_avgweg)
dplyr::count(qualinv_avgweg, quali_nv)

# how much variance in numeric variable is explained by categorical variable?
# funktion daraus erstellen und dann für jede nominale variable mit weglänge_avg machen

library(dplyr)

table_var <- group_by(qualinv_avgweg, quali_nv) %>%
  summarise(
    count = n(),
    mean = mean(Weglänge_avg, na.rm = TRUE),
    variance = var(Weglänge_avg, na.rm = TRUE),
    sd = sd(Weglänge_avg, na.rm = TRUE),
  )
table_var$var_before <- var(qualinv_avgweg$Weglänge_avg)
table_var$sd_before <- sd(qualinv_avgweg$Weglänge_avg)
table_var
#-> variance after grouping still at the same level: no correlation





```
```{r}
# für single: 

test_single <- HH_dt_final[, c("single", "Weglänge_avg")]
single1 <- filter(test_single, single == 1)
single0 <- filter(test_single, single == 0)

# check normal distribution of each category
# qq plot:
qqnorm(single1$Weglänge_avg, pch = 1, frame = FALSE)
qqline(single1$Weglänge_avg, col = "steelblue", lwd = 2)

qqnorm(single0$Weglänge_avg, pch = 1, frame = FALSE)
qqline(single0$Weglänge_avg, col = "steelblue", lwd = 2)


# check variance:
test_single$single <- factor(test_single$single)
leveneTest(Weglänge_avg ~ single, data = test_single)
boxplot(test_single$Weglänge_avg ~test_single$single)

summary(test_single)


# removing outliers

Q <- quantile(test_single$Weglänge_avg, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(test_single$Weglänge_avg)
eliminated<- subset(test_single, test_single$Weglänge_avg > (Q[1] - 1.5*iqr) & test_single$Weglänge_avg < (Q[2]+1.5*iqr))

boxplot(eliminated$Weglänge_avg ~ eliminated$single)
single1 <- filter(eliminated, single == 1)
single0 <- filter(eliminated, single == 0)
summary(single1)
summary(single0)
var(single1$Weglänge_avg)
var(single0$Weglänge_avg)
#--> variance is not equal, point-biserial not feasible

# couple

test_couple <- HH_dt_final[, c("couple", "Weglänge_avg")]
couple1 <- filter(test_couple, couple == 1)
couple0 <- filter(test_couple, couple == 0)

# check normal distribution of each category
# qq plot:
qqnorm(couple1$Weglänge_avg, pch = 1, frame = FALSE)
qqline(couple1$Weglänge_avg, col = "steelblue", lwd = 2)

qqnorm(couple0$Weglänge_avg, pch = 1, frame = FALSE)
qqline(couple0$Weglänge_avg, col = "steelblue", lwd = 2)


# check variance:
test_couple$couple <- factor(test_couple$couple)
leveneTest(Weglänge_avg ~ couple, data = test_couple)
boxplot(test_couple$Weglänge_avg ~test_couple$couple)

var(couple1$Weglänge_avg)
var(couple0$Weglänge_avg)
# variance almost equal
summary(couple1)
summary(couple0)

# do point-biserial:
install.packages('ltm')
library(ltm)
biserial.cor(test_couple$Weglänge_avg, test_couple$couple, use = c("all.obs"), level = 2)



# removing outliers -> makes variance difference greater -> just leave as it is and do point-biserial

Q <- quantile(test_couple$Weglänge_avg, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(test_couple$Weglänge_avg)
eliminated<- subset(test_couple, test_couple$Weglänge_avg > (Q[1] - 1.5*iqr) & test_couple$Weglänge_avg < (Q[2]+1.5*iqr))

boxplot(eliminated$Weglänge_avg ~ eliminated$single)
couple1 <- filter(eliminated, couple == 1)
couple0 <- filter(eliminated, couple == 0)

summary(couple1)
summary(couple0)
var(couple1$Weglänge_avg)
var(couple0$Weglänge_avg)
leveneTest(Weglänge_avg ~ couple, data = eliminated)

```

```{r}

```

