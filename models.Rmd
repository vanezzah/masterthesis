---
title: "models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Model 1

Regression using mnlogit

```{r}

HH_dt_2_out$numcars <- as.numeric(as.character(HH_dt_2_out$numcars))
HH_dt_2_out$numcars <- factor(HH_dt_2_out$numcars)

library(mlogit)

# transform data to long format
mnlogit_dt_out <- mlogit.data(HH_dt_2_out, choice = "numcars", shape = "wide") 

# Formula

#The formula should be specified in the format:  responseVar ~ choice specific variables withgeneric coefficients | individual specific variables | choice specific variables with choice specificcoefficients. These are the 3 available variable types.
#Any type of variables may be omitted. To omit use "1" as a placeholder.
#An alternative specific intercept is included by default in the estimation. To omit it, use a ’-1’ or’0’ anywhere in the formula.

#NULL MODEL (only intercept)
fm_null <- formula(numcars ~ 1 | 1 | 1)
fit_null <- mnlogit(fm_null, mnlogit_dt_out, ncores=4, choiceVar = "alt")

# model formulation normal
fm1 <- formula(numcars ~ 1 | numlic + region2 + income_numerical + 
    quali_nv + CSyes + workers + CSmultiple + nummots + housing_type + 
    triplength_avg + quali_opnv + oldHH + parttime + tripsavg + 
    hh_children + numped + metro28 + train28 + garage + bus28 | 1)
fit1 <- mnlogit(fm1, mnlogit_dt_out, ncores=4, choiceVar = "alt")

#with nonlinear terms
fm_new <- formula(numcars ~  1| numlic + region2 + income_numerical + I(numlic^2) + 
    quali_nv + I(income_numerical^2) + CSyes + workers + CSmultiple + 
    log(nummots1) + triplength_avg + housing_type + quali_opnv + 
    I(triplength_avg^2) + oldHH + parttime + hh_children + numped + 
    tripsavg + metro28 + train28 + garage + bus28 + I(parttime^2)|1)
fit_new <- mnlogit(fm_new, mnlogit_dt_out, ncores=4, choiceVar = "alt")

# compare normal and model featuring non-linear terms -> nonlinearity performs better
LL0 <- logLik(fit1)
LL1 <- logLik(fit_new)
N <- nrow(HH_dt_2_out)

lrtest(fit_new, fit1)

AIC(fit_new)
AIC(fit1)

# compare with null model 
LL0 <- logLik(fit_null)
LL1 <- logLik(fit_new)
N <- nrow(HH_dt_2_out)

#http://dwoll.de/rexrepos/posts/regressionMultinom.html#mcfadden-cox-snell-and-nagelkerke-pseudo-r2
#mc fadden pseudo r2 
mcfadden <- as.vector(1 - ((LL1) / (LL0)))

# cox and snell r2 
cox <- as.vector(1 - exp((2/N) * (LL0 - LL1)))

# nagelkerke r2
nagelkerke <- as.vector((1 - exp((2/N) * (LL0 - LL1))) / (1 - exp((2/N)*LL0)))

```

Model 1 - Model validation

```{r}

# z-statistics and z-tests of individual predictors:
summary(fit_new)

# Tests against the null-model

# Wald test

waldtest(fit_new, fit_null)


# Score test (using mlogit)
model1 <- mlogit(numcars ~  1| numlic + region2 + income_numerical + I(numlic^2) + 
    quali_nv + I(income_numerical^2) + CSyes + workers + CSmultiple + 
    log(nummots1) + triplength_avg + housing_type + quali_opnv + 
    I(triplength_avg^2) + oldHH + parttime + hh_children + numped + 
    tripsavg + metro28 + train28 + garage + bus28 + I(parttime^2), data = mnlogit_dt_out)
model2 <- mlogit(numcars ~ 1|numlic, data = mnlogit_dt_out)
mlogit::scoretest(model2, model1)

# Likelihood ratio test

lrtest(fit_null, fit_new)


# AIC:
AIC(fit_new)
AIC(fit_null)


```

Hosmer-Lemeshow standardization for large samples
```{r}
#n = 70294
#event number = 4
#target sample size= 500
#k=1000

#Sample a dataset with 500 rows from the big dataset that has the same distribution of outcomes as the real dataset
#do model on it
# do test on it 
# save HL statistic
# find distribution of HL statistic

dplyr::count(HH_dt_2_out,numcars)
#0	7467 -> 10.6%	-> 53		
#1	35909	-> 51% -> 255		
#2	21762	-> 31%	-> 155	
#3	5182 -> 7.4% -> 37

HL_dist <- as.matrix(data.frame(t(c("1"))))
colnames(HL_dist) <- c("Stat")

#! takes some time to compute
for (i in 1:1000){
 a<- sample(subset(HH_dt_2_out, numcars == "0"), 53)
 b<- sample(subset(HH_dt_2_out, numcars == "1"), 255)
 c <- sample(subset(HH_dt_2_out, numcars == "2"), 155)
 d<- sample(subset(HH_dt_2_out, numcars == "3"), 37)
 df_test <- rbind(a,b,c,d)
 
fit_HLsim <- multinom(numcars ~ numlic + region2 + income_numerical + I(numlic^2) + 
    quali_nv + I(income_numerical^2) + CSyes + workers + CSmultiple + 
    log(nummots1) + triplength_avg + housing_type + quali_opnv + 
    I(triplength_avg^2) + oldHH + parttime + hh_children + numped + 
    tripsavg + metro28 + train28 + garage + bus28 + I(parttime^2), data = df_test)
 
HLtest <- logitgof(df_test$numcars, fitted(fit_HLsim))
HLstat <- HLtest$statistic

HL_dist <- rbind(HL_dist, HLstat)

}

HL_dist <- as.data.frame(HL_dist)
HL_dist$Stat <- as.numeric(as.character(HL_dist$Stat))
hist(HL_dist$Stat)

#Xiquadrat verteilung für Xi(10-2) für 95% quantil: 15.51 / 2.73

prob = 1 - ecdf(HL_dist$Stat)(2.73)
prob
runif(1)

```


Results - Model 1

Coefficient table / Log-odds
```{r}
options(scipen = 999)

summary <- summary(fit_new)
coeffs <- summary$CoefTable
coeffs <- as.data.frame(coeffs)
coeffs <- rownames_to_column(coeffs)
coeffs$`t-value` <- NULL

coeffs1 <- coeffs[seq(1, 114, by=3),]
coeffs2 <- coeffs[seq(2, 114, by=3),]
coeffs3 <- coeffs[seq(3, 114, by=3),]

coeffs_total <- data.frame(coeffs1, coeffs2, coeffs3)
coeffs_total$rowname.1 <- NULL
coeffs_total$rowname.2 <- NULL

coeffs_total$rowname<-  sub(":1", "", coeffs_total$rowname)
coeffs_total$rowname[coeffs_total$rowname=="I(numlic^2)"] <- "licenses squared"
coeffs_total$rowname[coeffs_total$rowname=="I(parttime^2)"] <- "parttime squared"
coeffs_total$rowname[coeffs_total$rowname=="I(income_numerical^2)"] <- "income squared"
coeffs_total$rowname[coeffs_total$rowname=="I(triplength_avg^2)"] <- "av.triplength squared"
coeffs_total$rowname[coeffs_total$rowname=="log(nummots1)"] <- "motorbikes (log)"

coeffs_total$rowname[coeffs_total$rowname=="numlic"] <- "licenses"
coeffs_total$rowname[coeffs_total$rowname=="income_numerical"] <- "income"
coeffs_total$rowname[coeffs_total$rowname=="triplength_avg"] <- "av.triplength"
coeffs_total$rowname[coeffs_total$rowname=="workers"] <- "fulltime"
coeffs_total$rowname[coeffs_total$rowname=="numped"] <- "bikes"
coeffs_total$rowname[coeffs_total$rowname=="tripsavg"] <- "av.trips"
coeffs_total$rowname[coeffs_total$rowname=="CSyes1"] <- "carsharing"
coeffs_total$rowname[coeffs_total$rowname=="CSmultiple1"] <- "m.carsharing"
coeffs_total$rowname[coeffs_total$rowname=="nummots"] <- "motorbikes"
coeffs_total$rowname[coeffs_total$rowname=="parttime"] <- "parttime"
coeffs_total$rowname[coeffs_total$rowname=="region2suburban"] <- "suburban"
coeffs_total$rowname[coeffs_total$rowname=="region2rural"] <- "rural"
coeffs_total$rowname[coeffs_total$rowname=="oldHH1"] <- "old"
coeffs_total$rowname[coeffs_total$rowname=="hh_children1"] <- "children"
coeffs_total$rowname[coeffs_total$rowname=="housing_typemultifamily_h"] <- "multifamily"
coeffs_total$rowname[coeffs_total$rowname=="housing_typeapartmentbuilding"] <- "apartmentbuilding"
coeffs_total$rowname[coeffs_total$rowname=="housing_typeother"] <- "other"
coeffs_total$rowname[coeffs_total$rowname=="garage1"] <- "garage"

coeffs_total$rowname[coeffs_total$rowname=="quali_nv2"] <- "ps.2"
coeffs_total$rowname[coeffs_total$rowname=="quali_nv3"] <- "ps.3"
coeffs_total$rowname[coeffs_total$rowname=="quali_nv4"] <- "ps.4"


coeffs_total$rowname[coeffs_total$rowname=="quali_opnv2"] <- "pt.2"
coeffs_total$rowname[coeffs_total$rowname=="quali_opnv3"] <- "pt.3"
coeffs_total$rowname[coeffs_total$rowname=="quali_opnv4"] <- "pt.4"


coeffs_total$rowname[coeffs_total$rowname=="bus28_middle"] <- "bus.2"
coeffs_total$rowname[coeffs_total$rowname=="bus28_far"] <- "bus.3"
coeffs_total$rowname[coeffs_total$rowname=="bus28_rfar"] <- "bus.4"


coeffs_total$rowname[coeffs_total$rowname=="train28_middle"] <- "train.2"
coeffs_total$rowname[coeffs_total$rowname=="train28_far"] <- "train.3"
coeffs_total$rowname[coeffs_total$rowname=="train28_rfar"] <- "train.4"

coeffs_total$rowname[coeffs_total$rowname=="metro28_middle"] <- "metro.2"
coeffs_total$rowname[coeffs_total$rowname=="metro28_far"] <- "metro.3"
coeffs_total$rowname[coeffs_total$rowname=="metro28_rfar"] <- "metro.4"

colnames(coeffs_total)<- c("Variable","Parameter","Std. Error", "Sig1.", "Parameter","Std. Error", "Sig2.", "Parameter","Std. Error", "Sig3.")

for(i in 1:38) {
  if (coeffs_total$Sig1.[i] < 0.01) {
    coeffs_total$Sig1.[i] <- "***"
  }
  else if (coeffs_total$Sig1.[i] < 0.05) {
    coeffs_total$Sig1.[i] <- "**"
  }
  else if (coeffs_total$Sig1.[i] < 0.1) {
    coeffs_total$Sig1.[i] <- "*"
  }
  
  else{
    coeffs_total$Sig1.[i] <- ""
  }
}

for(i in 1:38) {
  if (coeffs_total$Sig2.[i] < 0.01) {
    coeffs_total$Sig2.[i] <- "***"
  }
  else if (coeffs_total$Sig2.[i] < 0.05) {
    coeffs_total$Sig2.[i] <- "**"
  }
   else if (coeffs_total$Sig2.[i] < 0.1) {
    coeffs_total$Sig2.[i] <- "*"
   }
  else{
    coeffs_total$Sig2.[i] <- ""
  }
}


for(i in 1:38) {
  if (coeffs_total$Sig3.[i] < 0.01) {
    coeffs_total$Sig3.[i] <- "***"
  }
  else if (coeffs_total$Sig3.[i] < 0.05) {
    coeffs_total$Sig3.[i] <- "**"
  }
   else if (coeffs_total$Sig3.[i] < 0.1) {
    coeffs_total$Sig3.[i] <- "*"
   }
  else{
    coeffs_total$Sig3.[i] <- ""
  }
 }


print(xtable(coeffs_total, type = "latex",digits=c(0,0,3,3,0,3,3,0,3,3,0)),include.rownames=FALSE, file = "coeffs_model.tex")
```
Odds ratios - Table
```{r}
#relative risk rates / the odds ratio 

# for relative risk ratio (odds) instead of log odds which is the output of the model
## extract the coefficients from the model and exponentiate
# The odds ratio of a coefficient indicates how the risk of the outcome falling in the comparison group compared to the risk of the outcome falling in the referent group changes with the variable in question.  An odds ratio > 1 indicates that the risk of the outcome falling in the comparison group relative to the risk of the outcome falling in the referent group increases as the variable increases.  In other words, the comparison outcome is more likely.  An odds ratio < 1 indicates that the risk of the outcome falling in the comparison group relative to the risk of the outcome falling in the referent group decreases as the variable increases.

coeffs_odds <- coeffs_total
coeffs_odds <- coeffs_odds[-c(3,4,6,7,9,10)]
coeffs_odds$Parameter <- exp(coeffs_odds$Parameter)
coeffs_odds$Parameter.1 <- exp(coeffs_odds$Parameter.1)
coeffs_odds$Parameter.2 <- exp(coeffs_odds$Parameter.2)

print(xtable(coeffs_odds, type = "latex",digits=c(0,0,3,3,3)),include.rownames=FALSE, file = "coeffs_odds.tex")
```

Average marginal effects

```{r}

#https://data.princeton.edu/wws509/r/mlogit

# average marginal effects
#Marginal effects are a useful way to describe the average effect of changes in explanatory variables on the change in the probability of outcomes in logistic regression and other nonlinear models.

#When comparing some category to the base outcome, a positive coefficient always means you are more likely to be in the comparison category than in the base category. However, when talking about the probability of being in a given category, the marginal effect (that is, the effect on the probability of being in a specific group by increasing the independent variable by one) does not have to be positive. This is because, in the former example, we are only comparing the two categories to one another. On the other hand, in the latter example, we are talking about comparing the probability of being in the comparison category not just to the base outcome (which will always be higher if the coefficient is positive) but also to the probability of being in all the other comparison groups.

#Let's assume we have gropus A, B, and C. A is the base outcome. If a coefficient on variable X is positive for group B, then increasing X will always make you more likely to be in B than A. However, increasing X does not necessarily make you more likely to be in group B, because the effect on the probability of being in group C may be even greater than the probability of being in group B, which means the marginal effect of X may actually be negative for group B (because you are more likely at this point to be in group C), but you are still more likely to be in group B than group A. 

#save.image(file='yoursession.RData')
library(miscTools)

# numlic
B <- coef(fit_new)
probs <- predict(fit_new, type="probs")
#B <- as.matrix(B)
b <- c(0,B[c("numlic:1", "numlic:2", "numlic:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r<- apply(me, 2, mean)
r <- c("numlic", r)
AVE_df <- as.matrix(data.frame(t(r)))
colnames(AVE_df) <- c("name", "zero_cars","1_car","2_cars","3_cars")


b <- c(0,B[c("I(numlic^2):1", "I(numlic^2):2", "I(numlic^2):3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r <- apply(me, 2, mean)
r <- c("I(numlic^2)", r)
AVE_df <- insertRow(AVE_df,1,r)

#We find that the average marginal effect of anzfs on having 2 cars is positive: 0.19. This means that the probability of having 2 cars is on average about 19 percentage points higher for households for a unit increase in drivers licenses in comparison with households with the same other variables. 

#Marginal Effect for Xk = P(Y=1 |X) * P(Y = 0|X) * bk.

b <- c(0,B[c("income_numerical:1", "income_numerical:2", "income_numerical:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r<- apply(me, 2, mean)
r <- c("income_numerical", r)
AVE_df <- insertRow(AVE_df,1,r)

#We find that the average marginal effect of einkommen2 on having 1 car is actually negative: -0.11. This means that the probability of having 1 car is on average about 11 percentage points lower for households in einkommen2 than for households in other einkommen groups with the same other variables. (for 1 car really heterogenous, therefore not that easy interpretable)


# marginal effects :
# To determine the effect of black in the probability scale we need to compute marginal effects, which can be done using continuous or discrete calculations. 
# We find that the average marginal effect of black on work is actually negative: -0.0406. This means that the probability of working is on average about four percentage points lower for blacks than for non-blacks with the same education and experience. 

# e.g. einkommen: 
# the log odds for einkommen2 to einkommen1 is 0.54 for having 1 car relative to 0 car, meaning it is more likely to have 1 car for people in einkommen2 than for people in einkommen1
# the relative risk rate for einkommen 2 to einkommen 1 is 1.72 for having 1 car relative to 0 cars, therefore it is more likely to have 1 car than zero cars when having einkommen2
# the relative probability of having 1 car rather than having 0 cars for people in einkommen 2 is 72% higher than the relative probability for people in einkommen1 with the same other variables!


# e.g. anzfs
# estimate for a one unit increase in anzfs for 1 car relative to 0 cars. if a household has one more drivers license, the log-odds of having 1 car relative to zero car would be expected to increase by 1.84
# the relative risk rate for an increase of 1 drivers license is 6.34 for having 1 car relative to 0 cars, therefore it is 6.34 times more likely to have 1 car than 0 cars when you have one drivers license more.


b <- c(0,B[c("triplength_avg:1", "triplength_avg:2", "triplength_avg:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r<-apply(me, 2, mean)
r <- c("triplength_avg", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("tripsavg:1", "tripsavg:2", "tripsavg:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("tripsavg")
r<- apply(me, 2, mean)
r <- c("tripsavg", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("log(nummots1):1", "log(nummots1):2", "log(nummots1):3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r<- apply(me, 2, mean)
r <- c("log(nummots1)", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("numped:1", "numped:2", "numped:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("numped")
r<- apply(me, 2, mean)
r <- c("numpeds", r)
AVE_df <- insertRow(AVE_df,1,r)

#b <- c(0,B[c("numch18:1", "numch18:2", "numch18:3")])
#pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
#me <- matrix(0, nrow(probs), ncol(probs))
#for(j in 1:4) {
#  me[,j] <- probs[,j] * (b[j] - pb)
#}
#print("numch18")
#r<- apply(me, 2, mean)
#r <- c("numch18", r)
#AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("workers:1", "workers:2", "workers:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("workers")
r<- apply(me, 2, mean)
r <- c("workers", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("parttime:1", "parttime:2", "parttime:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("parttime")
r<- apply(me, 2, mean)
r <- c("parttime", r)
AVE_df <- insertRow(AVE_df,1,r)

#b <- c(0,B[c("share2039:1", "share2039:2", "share2039:3")])
#pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
#me <- matrix(0, nrow(probs), ncol(probs))
#for(j in 1:4) {
#  me[,j] <- probs[,j] * (b[j] - pb)
#}
#print("share2039")
#r<- apply(me, 2, mean)
#r <- c("share2039", r)
#AVE_df <- insertRow(AVE_df,1,r)

#b <- c(0,B[c("share4064:1", "share4064:2", "share4064:3")])
#pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
#me <- matrix(0, nrow(probs), ncol(probs))
#for(j in 1:4) {
 # me[,j] <- probs[,j] * (b[j] - pb)
#}
#print("share4064")
#r<- apply(me, 2, mean)
#r <- c("share4064", r)
#AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("hh_children1:1", "hh_children1:2", "hh_children1:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("hh_children")
r<- apply(me, 2, mean)
r <- c("hh_children", r)
AVE_df <- insertRow(AVE_df,1,r)


b <- c(0,B[c("quali_nv2:1", "quali_nv2:2", "quali_nv2:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_nv2")
r<- apply(me, 2, mean)
r <- c("quali_nv2", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("quali_nv3:1", "quali_nv3:2", "quali_nv3:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_nv3")
r<- apply(me, 2, mean)
r <- c("quali_nv3", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("quali_nv4:1", "quali_nv4:2", "quali_nv4:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_nv4")
r<- apply(me, 2, mean)
r <- c("quali_nv4", r)
AVE_df <- insertRow(AVE_df,1,r)

# quali_opnv

b <- c(0,B[c("quali_opnv2:1", "quali_opnv2:2", "quali_opnv2:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_opnv2")
r<- apply(me, 2, mean)
r <- c("qualiopnv2", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("quali_opnv3:1", "quali_opnv3:2", "quali_opnv3:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_opnv3")
r<- apply(me, 2, mean)
r <- c("quali_opnv3", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("quali_opnv4:1", "quali_opnv4:2", "quali_opnv4:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("quali_opnv4")
r<- apply(me, 2, mean)
r <- c("quali_opnv4", r)
AVE_df <- insertRow(AVE_df,1,r)

#garage
b <- c(0,B[c("garage1:1", "garage1:2", "garage1:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("garage")
r<- apply(me, 2, mean)
r <- c("garage", r)
AVE_df <- insertRow(AVE_df,1,r)

#housing_type
b <- c(0,B[c("housing_typemultifamily_h:1", "housing_typemultifamily_h:2", "housing_typemultifamily_h:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("housing_typemultifamily_h")
r<- apply(me, 2, mean)
r <- c("housingtype_multifamilehome", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("housing_typeapartmentbuilding:1", "housing_typeapartmentbuilding:2", "housing_typeapartmentbuilding:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("housing_typeapartmentbuilding")
r<- apply(me, 2, mean)
r <- c("housing_type_apartmentbuilding", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("housing_typeother:1", "housing_typeother:2", "housing_typeother:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("housing_typeother")
r <- apply(me, 2, mean)
r <- c("housing_typeother", r)
AVE_df <- insertRow(AVE_df,1,r)

#metro
b <- c(0,B[c("metro28middle:1", "metro28middle:2", "metro28middle:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("metro28middle")
r<- apply(me, 2, mean)
r <- c("metro28middle", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("metro28far:1", "metro28far:2", "metro28far:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("metro28far")
r<- apply(me, 2, mean)
r <- c("metro28far", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("metro28rfar:1", "metro28rfar:2", "metro28rfar:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("metro28rfar")
r<- apply(me, 2, mean)
r <- c("metro28rfar", r)
AVE_df <- insertRow(AVE_df,1,r)

#bus
b <- c(0,B[c("bus28middle:1", "bus28middle:2", "bus28middle:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("bus28middle")
r<- apply(me, 2, mean)
r <- c("bus28middle", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("bus28far:1", "bus28far:2", "bus28far:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("bus28far")
r<- apply(me, 2, mean)
r <- c("bus28far", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("bus28rfar:1", "bus28rfar:2", "bus28rfar:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("bus28rfar")
r<- apply(me, 2, mean)
r <- c("bus28rfar", r)
AVE_df <- insertRow(AVE_df,1,r)

#train
b <- c(0,B[c("train28middle:1", "train28middle:2", "train28middle:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("train28middle")
r<- apply(me, 2, mean)
r <- c("train28middle", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("train28far:1", "train28far:2", "train28far:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("train28far")
r<- apply(me, 2, mean)
r <- c("train28far", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("train28rfar:1", "train28rfar:2", "train28rfar:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("train28rfar")
r<- apply(me, 2, mean)
r <- c("train28rfar", r)
AVE_df <- insertRow(AVE_df,1,r)

#region
b <- c(0,B[c("region2suburban:1", "region2suburban:2", "region2suburban:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("region2suburban")
r<- apply(me, 2, mean)
r <- c("suburban", r)
AVE_df <- insertRow(AVE_df,1,r)

b <- c(0,B[c("region2rural:1", "region2rural:2", "region2rural:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("region2rural")
r<- apply(me, 2, mean)
r <- c("rural", r)
AVE_df <- insertRow(AVE_df,1,r)

#CS
b <- c(0,B[c("CSyes1:1", "CSyes1:2", "CSyes1:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("CSyes")
r<- apply(me, 2, mean)
r <- c("CSyes", r)
AVE_df <- insertRow(AVE_df,1,r)



b <- c(0,B[c("CSmultiple1:1", "CSmultiple1:2", "CSmultiple1:3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
}
print("CSmultiple")
r<- apply(me, 2, mean)
r <- c("CSmultiple", r)
AVE_df <- insertRow(AVE_df,1,r)

AVE_df <- as.data.frame(AVE_df)


```


Compute Average marginal effects

```{r}

#!takes some time to compute!
# AMEs are calculated differently depending on the number of corresponding coefficients, first AMEs are calculated for variables with one level, than for variables with four levels and lastly for variables with three levels (e.g. region). Lastly, the AMEs for the number of motorbikes is computed separately, due to its logit transformation

AME_df_temp <- AME_df
#library(emmeans)
#emtrends(multinom_int3, ~ region2 , var = "garage", mode = "prob")

AME_df <- as.matrix(data.frame(t(c("name", "zero_cars","1_car","2_cars","3_cars"))))
colnames(AME_df) <- c("name", "zero_cars","one_car","two_cars","three_cars")

a.names <- names(fit_new$model)[- c(1, 22:25)]

names_num <- a.names[-c(2,4,8,10:11,17:18,20)]
names_cat <- a.names[c(4,10:11,17:18,20)]

  for(i in names_num){
  
  a <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = i,category="0")
  a_mean <- mean(a[,1])
  b <- marginal_effects(data=HH_dt_2_out, multinom_int3, variables = i,category="1")
  b_mean <- mean(b[,1])
  c <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = i,category="2")
  c_mean <- mean(c[,1])
  d <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables =i,category="3")
  d_mean <- mean(d[,1])
  v <- c(i,a_mean,b_mean,c_mean,d_mean)
  AME_df <- insertRow(AME_df,1,v)
}

  for(i in names_cat){
  
  a <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = i,category="0")
  a_mean <- mean(a[,1])
  a_mean2 <- mean(a[,2])
  a_mean3 <- mean(a[,3])
  b <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = i,category="1")
  b_mean <- mean(b[,1])
  b_mean2 <- mean(b[,2])
  b_mean3 <- mean(b[,3])
  c <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = i,category="2")
  c_mean <- mean(c[,1])
  c_mean2 <- mean(c[,2])
  c_mean3 <- mean(c[,3])
  d <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables =i,category="3")
  d_mean <- mean(d[,1])
  d_mean2 <- mean(d[,2])
  d_mean3 <- mean(d[,3])

  v <- c(paste0(i,"2"),a_mean,b_mean,c_mean,d_mean)
  v2 <- c(paste0(i,"3"),a_mean2,b_mean2,c_mean2,d_mean2)
  v3 <- c(paste0(i,"4"),a_mean3,b_mean3,c_mean3,d_mean3)
  AME_df <- insertRow(AME_df,1,v)
  AME_df <- insertRow(AME_df,1,v2)
  AME_df <- insertRow(AME_df,1,v3)
  }


# region Variable

 a <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = "region2",category="0")
  a_mean <- mean(a[,1])
  a_mean2 <- mean(a[,2])
  b <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = "region2",category="1")
  b_mean <- mean(b[,1])
  b_mean2 <- mean(b[,2])
  c <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = "region2",category="2")
  c_mean <- mean(c[,1])
  c_mean2 <- mean(c[,2])
  d <- marginal_effects(data=HH_dt_2_out, fit_multinom_v3, variables = "region2",category="3")
  d_mean <- mean(d[,1])
  d_mean2 <- mean(d[,2])

  v <- c(paste0("region2","suburban"),a_mean,b_mean,c_mean,d_mean)
  v2 <- c(paste0("region2","rural"),a_mean2,b_mean2,c_mean2,d_mean2)
  
  AME_df <- insertRow(AME_df,1,v)
  AME_df <- insertRow(AME_df,1,v2)
  

# log nummots
#interpreting log transformed variables:
  #https://stats.stackexchange.com/questions/8318/interpretation-of-log-transformed-predictors-in-logistic-regression
#https://stats.stackexchange.com/questions/215599/log-transformation-logistic-regression

B <- coef(fit_new)
b <- c(0,B[c("log(nummots1):1", "log(nummots1):2", "log(nummots1):3")])
pb <- probs[,2] * b[2]  + probs[,3] * b[3] + probs[,4] * b[4]
me <- matrix(0, nrow(probs), ncol(probs))
for(j in 1:4) {
  me[,j] <- probs[,j] * (b[j] - pb)
 }
r<- apply(me, 2, mean)
v <- c("log(nummots1)", r)
AME_df <- insertRow(AME_df,1,v)

AME_df <- AME_df[-c(34),]

AME_df <- as.data.frame(AME_df)
AME_df$zero_cars <- as.numeric(as.character((AME_df$zero_cars)))
AME_df$zero_cars <- round(AME_df$zero_cars,3)

AME_df$one_car <- as.numeric(as.character((AME_df$one_car)))
AME_df$one_car <- round(AME_df$one_car,3)

AME_df$two_cars <- as.numeric(as.character((AME_df$two_cars)))
AME_df$two_cars <- round(AME_df$two_cars,3)

AME_df$three_cars <- as.numeric(as.character((AME_df$three_cars)))
AME_df$three_cars <- round(AME_df$three_cars,3)

#make table
AME_df$name <- as.character(AME_df$name)
AME_df$name[AME_df$name=="numlic"] <- "licenses"
AME_df$name[AME_df$name=="income_numerical"] <- "income"
AME_df$name[AME_df$name=="triplength_avg"] <- "av.triplength"
AME_df$name[AME_df$name=="workers"] <- "fulltime"
AME_df$name[AME_df$name=="numped"] <- "bikes"
AME_df$name[AME_df$name=="tripsavg"] <- "av.trips"
AME_df$name[AME_df$name=="CSyes"] <- "carsharing"
AME_df$name[AME_df$name=="CSmultiple"] <- "m.carsharing"
AME_df$name[AME_df$name=="log(nummots1)"] <- "motorbikes"
AME_df$name[AME_df$name=="parttime"] <- "parttime"
AME_df$name[AME_df$name=="region2suburban"] <- "suburban"
AME_df$name[AME_df$name=="region2rural"] <- "rural"
AME_df$name[AME_df$name=="oldHH"] <- "old"
AME_df$name[AME_df$name=="hh_children"] <- "children"
AME_df$name[AME_df$name=="housing_type2"] <- "multifamily"
AME_df$name[AME_df$name=="housing_type3"] <- "apartmentbuilding"
AME_df$name[AME_df$name=="housing_type4"] <- "other"
AME_df$name[AME_df$name=="garage"] <- "garage"

AME_df$name[AME_df$name=="quali_nv2"] <- "ps.2"
AME_df$name[AME_df$name=="quali_nv3"] <- "ps.3"
AME_df$name[AME_df$name=="quali_nv4"] <- "ps.4"


AME_df$name[AME_df$name=="quali_opnv2"] <- "pt.2"
AME_df$name[AME_df$name=="quali_opnv3"] <- "pt.3"
AME_df$name[AME_df$name=="quali_opnv4"] <- "pt.4"


AME_df$name[AME_df$name=="bus282"] <- "bus.2"
AME_df$name[AME_df$name=="bus283"] <- "bus.3"
AME_df$name[AME_df$name=="bus284"] <- "bus.4"


AME_df$name[AME_df$name=="train282"] <- "train.2"
AME_df$name[AME_df$name=="train283"] <- "train.3"
AME_df$name[AME_df$name=="train284"] <- "train.4"

AME_df$name[AME_df$name=="metro282"] <- "metro.2"
AME_df$name[AME_df$name=="metro283"] <- "metro.3"
AME_df$name[AME_df$name=="metro284"] <- "metro.4"

```

Standardized coefficients
```{r}
importance_ml <- as.data.frame(coef(fit_new))
importance_ml <- rownames_to_column(importance_ml)
importance_ml1 <- importance_ml[1:38,]
importance_ml2 <- importance_ml[39:76,]
importance_ml3 <- importance_ml[77:114,]
importance_ml_final <- data.frame(importance_ml1, importance_ml2, importance_ml3)
importance_ml_final$rowname.1 <- NULL
importance_ml_final$rowname.2 <- NULL
colnames(importance_ml_final)<- c("Variable","One car","Two cars", "Three and more cars")
importance_ml_final <- importance_ml_final[order(importance_ml_final$Variable),]
importance_ml_final <- filter(importance_ml_final, Variable!= c("(Intercept):1"))
importance_ml_final <- filter(importance_ml_final, Variable!= c("I(numlic^2):1"))
importance_ml_final <- filter(importance_ml_final, Variable!= c("I(income_numerical^2):1"))
importance_ml_final <- filter(importance_ml_final, Variable!= c("I(triplength_avg^2):1"))
importance_ml_final <- filter(importance_ml_final, Variable!= c("I(workers^2):1"))
importance_ml_final <- filter(importance_ml_final, Variable!= c("I(parttime^2):1"))

#standard deviation of variables
relevant_vars <- names(fit_new$model)[2:21]
SD_df <- HH_dt_2_out[,relevant_vars, with=FALSE] 
alloc.col(SD_df, 200)
test_dummies <- fastDummies::dummy_cols(SD_df, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
test_dummies$nummots1 <- log(test_dummies$nummots1)
names(test_dummies)[names(test_dummies) == 'nummots1'] <- 'log(nummots1)'
variables_SD <- apply(test_dummies,2,sd)
variables_SD <- as.data.frame(variables_SD)
variables_SD <- rownames_to_column(variables_SD)
variables_SD <- variables_SD[order(variables_SD$rowname),]

# calculate standardized coefficients
importance_f <- importance_ml_final
result_importance <- data.frame(importance_f, variables_SD)
result_importance$standardized_coef_1 <- abs(result_importance$One.car * result_importance$variables_SD)
result_importance$standardized_coef_2 <- abs(result_importance$Two.cars * result_importance$variables_SD)
result_importance$standardized_coef_3 <- abs(result_importance$Three.and.more.cars * result_importance$variables_SD)
result_importance$standardized_coef_total <- result_importance$standardized_coef_1 + result_importance$standardized_coef_2 + result_importance$standardized_coef_3

result_importance <- result_importance[order(result_importance$standardized_coef_total, decreasing=TRUE),]

result_importance2<- data.frame(result_importance$rowname,result_importance$standardized_coef_total)
colnames(result_importance2)<- c("rowname","Standardizedcoef")
result_importance2$rank <- c(1:33)
result_importance2$relimp <- result_importance2$Standardizedcoef/sum(result_importance2$Standardizedcoef)

# change names
result_importance2$rowname <- as.character(result_importance2$rowname)
result_importance2$rowname<-  sub("_", "", result_importance2$rowname)
result_importance2$rowname<-  sub("_", "", result_importance2$rowname)

result_importance2$rowname[result_importance2$rowname=="log(nummots1)"] <- "motorbikes"
result_importance2$rowname[result_importance2$rowname=="numlic"] <- "licenses"
result_importance2$rowname[result_importance2$rowname=="incomenumerical"] <- "income"
result_importance2$rowname[result_importance2$rowname=="triplengthavg"] <- "av.triplength"
result_importance2$rowname[result_importance2$rowname=="workers"] <- "fulltime"
result_importance2$rowname[result_importance2$rowname=="numped"] <- "bikes"
result_importance2$rowname[result_importance2$rowname=="tripsavg"] <- "av.trips"
result_importance2$rowname[result_importance2$rowname=="CSyes1"] <- "carsharing"
result_importance2$rowname[result_importance2$rowname=="CSmultiple1"] <- "m.carsharing"
result_importance2$rowname[result_importance2$rowname=="parttime"] <- "parttime"
result_importance2$rowname[result_importance2$rowname=="region2suburban"] <- "suburban"
result_importance2$rowname[result_importance2$rowname=="region2rural"] <- "rural"
result_importance2$rowname[result_importance2$rowname=="oldHH1"] <- "old"
result_importance2$rowname[result_importance2$rowname=="hh_children1"] <- "children"
result_importance2$rowname[result_importance2$rowname=="housingtypemultifamily_h"] <- "multifamily"
result_importance2$rowname[result_importance2$rowname=="housingtypeapartmentbuilding"] <- "apartmentbuilding"
result_importance2$rowname[result_importance2$rowname=="housingtypeother"] <- "other"
result_importance2$rowname[result_importance2$rowname=="garage1"] <- "garage"

result_importance2$rowname[result_importance2$rowname=="qualinv2"] <- "ps.2"
result_importance2$rowname[result_importance2$rowname=="qualinv3"] <- "ps.3"
result_importance2$rowname[result_importance2$rowname=="qualinv4"] <- "ps.4"

result_importance2$rowname[result_importance2$rowname=="qualiopnv2"] <- "pt.2"
result_importance2$rowname[result_importance2$rowname=="qualiopnv3"] <- "pt.3"
result_importance2$rowname[result_importance2$rowname=="qualiopnv4"] <- "pt.4"

result_importance2$rowname[result_importance2$rowname=="bus28middle"] <- "bus.2"
result_importance2$rowname[result_importance2$rowname=="bus28far"] <- "bus.3"
result_importance2$rowname[result_importance2$rowname=="bus28rfar"] <- "bus.4"

result_importance2$rowname[result_importance2$rowname=="train28middle"] <- "train.2"
result_importance2$rowname[result_importance2$rowname=="train28far"] <- "train.3"
result_importance2$rowname[result_importance2$rowname=="train28rfar"] <- "train.4"

result_importance2$rowname[result_importance2$rowname=="metro28middle"] <- "metro.2"
result_importance2$rowname[result_importance2$rowname=="metro28far"] <- "metro.3"
result_importance2$rowname[result_importance2$rowname=="metro28rfar"] <- "metro.4"

```

Merge AMEs and standardized coefficients and make table

```{r}

table_AMEstand <- merge(AME_df, result_importance2, by.x = "name", by.y="rowname")
table_AMEstand<- table_AMEstand[order(table_AMEstand$rank, decreasing=FALSE),]

print(xtable(table_AMEstand, type = "latex",digits=c(0,0,3,3,3,3,1,0,2)),include.rownames=FALSE, file = "AME2stand.tex")

```


Forward selection (normal model)

```{r}


#fit_multinom_test <- multinom(numcars ~ numlic + I(numlic^2) + region2 + income_numerical+ quali_nv + CSyes + CSmultiple + workers +triplength_avg+ I(triplength_avg^2) + log(nummots1)+ housing_type + quali_opnv + share2039 + share4064 + hh_children + garage + metro28 + train28 + tripsavg + parttime + numped + bus28 + education + numch18, data = HH_dt_2_out)

fit_multinom_null <- multinom(numcars ~ 1, data = HH_dt_2_out,maxit=300)

result_stepAIC1 <- stepAIC(fit_multinom_null, direction="forward", scope = list(upper = ~ numlic + region2 + income_numerical+ quali_nv + CSyes + CSmultiple + workers  + triplength_avg+ nummots+ housing_type + quali_opnv + oldHH + hh_children + garage + metro28 + train28 + tripsavg + parttime + numped + bus28))

result_stepAIC1

stepAIC(fit_multinom_null, direction="forward", scope = list(upper = ~ numlic + I(numlic^2) + region2 + income_numerical+I(income_numerical^2)+ quali_nv + CSyes + CSmultiple + workers + I(workers^2) + triplength_avg+ I(triplength_avg^2) + log(nummots1)+ housing_type + quali_opnv + oldHH+ hh_children + garage + metro28 + train28 + tripsavg + parttime + numped + bus28))


#statt rotate x axis ding:
# scale_x_discrete(guide = guide_axis(n.dodge = 2))



fm_new <- formula(numcars ~  1| numlic + I(numlic^2) + region2 + income_numerical+ quali_nv + CSyes + CSmultiple + workers +triplength_avg+ I(triplength_avg^2) + log(nummots1)+ housing_type + quali_opnv + share2039 + share4064 + hh_children + garage + metro28 + train28 + tripsavg + parttime + numped + bus28|1)
fit_new <- mnlogit(fm_new, mnlogit_dt_out, ncores=4, choiceVar = "alt")
as.vector(1 - (logLik(fit_new) / LL0))

summary(fit_new)

logitgof(HH_dt_2_out$numcars, fitted(fit_interaction, outcome = FALSE))

#mc fadden:
as.vector(1 - (logLik(fit_new) / LL0))

```


Forward selection (interaction model)

```{r}

fm_adapted <- formula(numcars ~  1| numlic + I(numlic^2) + region2 + income_numerical+ I(income_numerical^2) + quali_nv + CSyes + CSmultiple + workers + I(workers^2) + triplength_avg+ I(triplength_avg^2) + log(nummots1)+ housing_type + quali_opnv + share2039 + I(share2039^2)+ share4064 + I(share4064^2) +hh_children + garage + metro28 + train28 + tripsavg + I(tripsavg^2)+ parttime + I(parttime^2)+ numped + I(numped^2)+ bus28 |1)
fit_adapated <- mnlogit(fm_adapted, mnlogit_dt_out, ncores=4, choiceVar = "alt")

fm_interaction <-formula(numcars ~  1|region2 + numlic + I(numlic^2) + region2:numlic + region2:I(numlic^2) + income_numerical +I(income_numerical^2)+ region2:income_numerical + region2:I(income_numerical^2) + quali_nv + region2:quali_nv + CSyes + region2:CSyes + workers+ I(workers^2)+region2:workers + triplength_avg+ I(triplength_avg^2)+ region2:triplength_avg+ region2:I(triplength_avg^2) + log(nummots1) + housing_type + garage + quali_opnv + share2039 + I(share2039^2)  +  region2:share2039 + region2:I(share2039^2) + share4064 + CSmultiple+ hh_children + region2:hh_children + metro28 +tripsavg + parttime + train28 +numped + I(numped^2) + region2:numped + region2:I(numped^2) |1)
fit_interaction <- mnlogit(fm_interaction, mnlogit_dt_out, ncores=4, choiceVar = "alt")
as.vector(1 - ((logLik(fit_interaction)) / (logLik(fit_null))))

#fm_interaction <- formula(numcars ~  1| numlic + I(numlic^2) + region2 + income_numerical+ I(income_numerical^2) + quali_nv + CSyes + CSmultiple + workers + I(workers^2) + triplength_avg+ I(triplength_avg^2) + log(nummots1)+ housing_type + quali_opnv + share2039 + I(share2039^2)+ share4064 + I(share4064^2) +hh_children + garage + metro28 + train28 + tripsavg + parttime + I(parttime^2)+ numped + I(numped^2)+ bus28 + region2:income_numerical + region2:I(income_numerical^2) + region2:quali_nv + region2:CSyes + region2:workers + region2:triplength_avg + region2:numped + region2:garage + region2:share2039 + region2:share4064 + region2:parttime + region2:numlic + region2:I(numlic^2) |1)

fit_interaction <- mnlogit(fm_interaction, mnlogit_dt_out, ncores=4, choiceVar = "alt")
summary(fit_interaction)

#mc fadden pseudo r2 
as.vector(1 - ((logLik(fit_interaction)) / (logLik(fit_null))))

AIC(fit_interaction) - AIC(fit_adapated)

```

# for 0 cars
```{r}

#AME_temp <- AME_int
library(margins)

test_margins0 <- margins(multinom_int3, variables=c("numlic","income_numerical","CSyes", "workers", "parttime", "hh_children", "oldHH", "garage", "numped", "triplength_avg","quali_nv", "housing_type", "train28"), data = data.frame(HH_dt_2_out), at = list("region2"=c("urban", "suburban", "rural")), category = "0")

test_margins1 <- margins(multinom_int3, variables=c("numlic","income_numerical","CSyes", "workers", "parttime", "hh_children", "oldHH", "garage", "numped", "triplength_avg", "quali_nv", "housing_type", "train28"), data = data.frame(HH_dt_2_out), at = list("region2"=c("urban", "suburban", "rural")), category = "1")

test_margins2 <- margins(multinom_int3, variables=c("numlic","income_numerical","CSyes", "workers", "parttime", "hh_children", "oldHH", "garage", "numped", "triplength_avg", "quali_nv", "housing_type", "train28"), data = data.frame(HH_dt_2_out), at = list("region2"=c("urban", "suburban", "rural")), category = "2")

test_margins3 <- margins(multinom_int3, variables=c("numlic","income_numerical","CSyes", "workers", "parttime", "hh_children", "oldHH", "garage", "numped", "triplength_avg", "quali_nv", "housing_type", "train28"), data = data.frame(HH_dt_2_out), at = list("region2"=c("urban", "suburban", "rural")), category = "3")

test_margins0_df <- as.data.frame(summary(test_margins0))
test_margins0_df[,3:7] <- NULL
test_margins0_df <- reshape(test_margins0_df, idvar = "factor", timevar = "region2", direction = "wide")

test_margins1_df <- as.data.frame(summary(test_margins1))
test_margins1_df[,4:8] <- NULL
test_margins1_df <- reshape(test_margins1_df, idvar = "factor", timevar = "region2", direction = "wide")

test_margins2_df <- as.data.frame(summary(test_margins2))
test_margins2_df[,4:8] <- NULL
test_margins2_df <- reshape(test_margins2_df, idvar = "factor", timevar = "region2", direction = "wide")

test_margins3_df <- as.data.frame(summary(test_margins3))
test_margins3_df[,4:8] <- NULL
test_margins3_df <- reshape(test_margins3_df, idvar = "factor", timevar = "region2", direction = "wide")

margins_total <- cbind(test_margins0_df, test_margins1_df, test_margins2_df, test_margins3_df)
margins_total[,c(5,9,13)] <- NULL

print(xtable(margins_total, type = "latex", digits=c(0,0,3,3,3,3,3,3,3,3,3,3,3,3)), include.rownames=FALSE, file = "margins_int.tex")

# test significance of differences in interaction effects between regions: 

AME_int2 <- as.matrix(data.frame(t(c("name","pvalue1", "pvalue2", "pvalue3"))))
names_numint <- names_num[c(1,2,3,4,6,7,8,9,10,12)]
  for(i in names_numint){
  tempurb <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "urban"], multinom_int3,variables= i,category = "0") 
  mean_urb <- mean(tempurb[,1])
  tempsub <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "suburban"], multinom_int3,variables= i,category = "0")  
  mean_sub <- mean(tempsub[,1])
  temprur <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "rural"], multinom_int3,variables= i,category = "0")  
  mean_rur <- mean(temprur[,1])
  
  testa <- t.test(tempurb[,1],tempsub[,1], paired = FALSE)
  testb <- t.test(tempurb[,1],temprur[,1], paired = FALSE)
  testc <- t.test(tempsub[,1],temprur[,1], paired = FALSE)
  
  res1 = round(mean_urb - mean_sub,3)
  if(testa$p.value < 0.01) 
  {res1 = paste0("**")}
  else if (testa$p.value < 0.05) 
  {res1 = paste0("*")}
  
  res2 = round(mean_urb - mean_rur,3)
  if(testb$p.value < 0.01) 
  {res2 = paste0("**")}
  else if (testa$p.value < 0.05) 
  {res2 = paste0("*")}
  
  res3 = round(mean_sub - mean_rur,3)
  if(testc$p.value < 0.01) 
  {res3 = paste0("**")}
  else if (testa$p.value < 0.05) 
  {res3 = paste0("*")}
  
  w <- c(i, res1, res2, res3)
  AME_int2 <- insertRow(AME_int2,1,w)
  }

names_catint <- names_cat[c(1,2,5)]
for(i in names_catint){
  tempurb <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "urban"], multinom_int2,variables= i,category = "0")  
  mean_urb <- mean(tempurb[,1])
  mean_urb2<- mean(tempurb[,2])
  mean_urb3 <- mean(tempurb[,3])
  tempsub <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "suburban"], multinom_int2,variables= i,category = "0")  
  mean_sub <- mean(tempsub[,1])
  mean_sub2<- mean(tempsub[,2])
  mean_sub3<- mean(tempsub[,3])
  temprur <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "rural"], multinom_int2,variables= i,category = "0")  
  mean_rur <- mean(temprur[,1])
  mean_rur2<- mean(temprur[,2])
  mean_rur3<- mean(temprur[,3])
  
  testa <- wilcox.test(tempurb[,1],tempsub[,1], paired = FALSE)
  testb <- wilcox.test(tempurb[,1],temprur[,1], paired = FALSE)
  testc <- wilcox.test(tempsub[,1],temprur[,1], paired = FALSE)
  
  testa2 <- wilcox.test(tempurb[,2],tempsub[,2], paired = FALSE)
  testb2 <- wilcox.test(tempurb[,2],temprur[,2], paired = FALSE)
  testc2 <- wilcox.test(tempsub[,2],temprur[,2], paired = FALSE)
  
  testa3 <- wilcox.test(tempurb[,3],tempsub[,3], paired = FALSE)
  testb3 <- wilcox.test(tempurb[,3],temprur[,3], paired = FALSE)
  testc3 <- wilcox.test(tempsub[,3],temprur[,3], paired = FALSE)
  
  res1 = round(mean_urb - mean_sub,3)
  if(testa$p.value < 0.01) 
  {res1 = paste0(round(mean_urb - mean_sub,3),"*")}
  res2 = round(mean_urb - mean_rur,3)
  if(testb$p.value < 0.01) 
  {res2 = paste0(round(mean_urb - mean_rur,3),"*")}
  res3 = round(mean_sub - mean_rur,3)
  if(testc$p.value < 0.01) 
  {res3 = paste0(round(mean_sub - mean_rur,3),"*")}
  
    res1a = round(mean_urb2 - mean_sub2,3)
  if(testa2$p.value < 0.01) 
  {res1a = paste0(round(mean_urb2 - mean_sub2,3),"*")}
  res2a = round(mean_urb2 - mean_rur2,3)
  if(testb2$p.value < 0.01) 
  {res2a = paste0(round(mean_urb2 - mean_rur2,3),"*")}
  res3a = round(mean_sub2 - mean_rur2,3)
  if(testc2$p.value < 0.01) 
  {res3a = paste0(round(mean_sub2 - mean_rur2,3),"*")}
  
    res1b = round(mean_urb3 - mean_sub3,3)
  if(testa3$p.value < 0.01) 
  {res1b = paste0(round(mean_urb3 - mean_sub3,3),"*")}
  res2b = round(mean_urb3 - mean_rur3,3)
  if(testb3$p.value < 0.01) 
  {res2b = paste0(round(mean_urb3 - mean_rur3,3),"*")}
  res3b = round(mean_sub3 - mean_rur3,3)
  if(testc3$p.value < 0.01) 
  {res3b = paste0(round(mean_sub3 - mean_rur3,3),"*")}
  
  w <- c(i,round(mean_urb,3),round(mean_sub,3),round(mean_rur,3), res1, res2, res3)
  w2 <- c(i,round(mean_urb2,3),round(mean_sub2,3),round(mean_rur2,3), res1a, res2a, res3a)
  w3 <- c(i,round(mean_urb3,3),round(mean_sub3,3),round(mean_rur3,3), res1b, res2b, res3b)
  
  AME_int <- insertRow(AME_int,1,w)
  AME_int <- insertRow(AME_int,1,w2)
  AME_int <- insertRow(AME_int,1,w3)
}

AME_inttotal <- data.frame(AME_int, AME_int1)

```

Test significance of interaction effects

```{r}


tempurb <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "urban"], multinom_int3,variables= i,category = "1") 

AME_int1 <- as.matrix(data.frame(t(c("name", "urban","suburban","rural","pvalue1", "pvalue2", "pvalue3"))))
colnames(AME_int1) <- c("name", "urban","suburban","rural","pvalue1", "pvalue2", "pvalue3")
for(i in names_numint){
  tempurb <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "urban"], multinom_int3,variables= i,category = "1")  
  mean_urb <- mean(tempurb[,1])
  tempsub <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "suburban"], multinom_int3,variables= i,category = "1")  
  mean_sub <- mean(tempsub[,1])
  temprur <- marginal_effects(data = HH_dt_2_out[HH_dt_2_out$region2 == "rural"], multinom_int3,variables= i,category = "1")  
  mean_rur <- mean(temprur[,1])
  
  testa <- wilcox.test(tempurb[,1],tempsub[,1], paired = FALSE)
  testb <- wilcox.test(tempurb[,1],temprur[,1], paired = FALSE)
  testc <- wilcox.test(tempsub[,1],temprur[,1], paired = FALSE)
  
  res1 = round(mean_urb - mean_sub,3)
  if(testa$p.value < 0.01) 
  {res1 = paste0(round(mean_urb - mean_sub,3),"*")}
  else {res1 = "none"}
  
  res2 = round(mean_urb - mean_rur,3)
  if(testb$p.value < 0.01) 
    {res2 = paste0(round(mean_urb - mean_rur,3),"*")}
  else {res2 = "none"}
  res3 = round(mean_sub - mean_rur,3)
  if(testc$p.value < 0.01) 
  {res3 = paste0(round(mean_sub - mean_rur,3),"*")}
  else {res3 = "none"}
  
  w <- c(i,round(mean_urb,3),round(mean_sub,3),round(mean_rur,3), res1, res2, res3)
  AME_int1 <- insertRow(AME_int1,1,w)
}
```



